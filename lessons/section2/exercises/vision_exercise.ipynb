{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanation of the code:\n",
    "\n",
    "This code demonstrates how to use the OpenAI API for vision tasks, specifically for analyzing images using the `gpt-4o-mini` model. It shows two ways to provide images to the model: using an image URL and using a Base64 encoded image.\n",
    "\n",
    "### 1. Analyzing Image from URL\n",
    "\n",
    "This section shows how to analyze an image by providing its URL to the OpenAI API.\n",
    "\n",
    "**Steps:**\n",
    "\n",
    "1. **Import OpenAI library:**\n",
    "   - `from openai import OpenAI`: Imports the OpenAI Python library.\n",
    "\n",
    "2. **Initialize OpenAI client:**\n",
    "   - `client = OpenAI()`: Creates an OpenAI client object.\n",
    "\n",
    "3. **Send request to chat completions API with image URL:**\n",
    "   - `response = client.chat.completions.create(...)`: Calls the `chat.completions.create` method to analyze the image.\n",
    "     - `model=\"gpt-4o-mini\"`: Specifies the `gpt-4o-mini` model, which is suitable for vision tasks.\n",
    "     - `messages=[...]`: Defines the messages for the chat completion.\n",
    "       - `{\"role\": \"user\", \"content\": [...]}`: User message containing both text and image content.\n",
    "         - `{\"type\": \"text\", \"text\": \"What's in this image?\"}`: Text part of the prompt asking about the image content.\n",
    "         - `{\"type\": \"image_url\", \"image_url\": {\"url\": \"...\"}}`: Image URL part, providing the URL of the image to be analyzed. In this case, it's a URL of a nature boardwalk image from Wikimedia Commons.\n",
    "     - `max_tokens=300`:  Limits the maximum number of tokens in the response.\n",
    "\n",
    "4. **Print the response:**\n",
    "   - `print(response.choices[0])`: Prints the response from the OpenAI API, which will contain the model's description of the image content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image features a serene landscape showcasing a wooden pathway that stretches through a lush green field. The path appears to lead into the distance, surrounded by tall grasses and scattered bushes. The sky is bright with scattered clouds, indicating a clear day, and the overall scene conveys a sense of tranquility and natural beauty.\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "\tmodel=\"gpt-4o-mini\",\n",
    "\tmessages=[\n",
    "\t\t{\n",
    "\t\t\t\"role\": \"user\",\n",
    "\t\t\t\"content\": [\n",
    "\t\t\t\t{\"type\": \"text\", \"text\": \"What's in this image?\"},\n",
    "\t\t\t\t{\n",
    "\t\t\t\t\t\"type\": \"image_url\",\n",
    "\t\t\t\t\t\"image_url\": {\n",
    "\t\t\t\t\t\t\"url\": \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/Gfp-wisconsin-madison-the-nature-boardwalk.jpg/2560px-Gfp-wisconsin-madison-the-nature-boardwalk.jpg\",\n",
    "\t\t\t\t\t},\n",
    "\t\t\t\t},\n",
    "\t\t\t],\n",
    "\t\t}\n",
    "\t],\n",
    "\tmax_tokens=300,\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beginner Exercise:\n",
    "\n",
    "**Task:** Modify the code in \"Analyzing Image from URL\" section to analyze a different image from a URL of your choice and print the response.\n",
    "\n",
    "**Hint:**\n",
    "   - Find a new image URL online.\n",
    "   - Replace the existing image URL in the code with your new URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Analyzing Image from Base64 Encoding\n",
    "\n",
    "This section demonstrates how to analyze an image by providing its Base64 encoded string to the OpenAI API. This is useful when you have the image data readily available in your code or when you want to send local images without making them publicly accessible via a URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'path_to_your_image.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m image_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpath_to_your_image.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;66;03m# Replace with your image path\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# Getting the Base64 string\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m base64_image \u001b[38;5;241m=\u001b[39m \u001b[43mencode_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m response \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mchat\u001b[38;5;241m.\u001b[39mcompletions\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[0;32m     18\u001b[0m \tmodel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-4o-mini\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     19\u001b[0m \tmessages\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     33\u001b[0m \t],\n\u001b[0;32m     34\u001b[0m )\n\u001b[0;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent)\n",
      "Cell \u001b[1;32mIn[6], line 8\u001b[0m, in \u001b[0;36mencode_image\u001b[1;34m(image_path)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mencode_image\u001b[39m(image_path):\n\u001b[1;32m----> 8\u001b[0m \t\u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m image_file:\n\u001b[0;32m      9\u001b[0m \t\t\u001b[38;5;28;01mreturn\u001b[39;00m base64\u001b[38;5;241m.\u001b[39mb64encode(image_file\u001b[38;5;241m.\u001b[39mread())\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\eyalra\\AppData\\Local\\miniconda3\\envs\\genaienv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'path_to_your_image.jpg'"
     ]
    }
   ],
   "source": [
    "import base64\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "# Function to encode the image\n",
    "def encode_image(image_path):\n",
    "\twith open(image_path, \"rb\") as image_file:\n",
    "\t\treturn base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "\n",
    "# Path to your image\n",
    "image_path = \"path_to_your_image.jpg\" # Replace with your image path\n",
    "\n",
    "# Getting the Base64 string\n",
    "base64_image = encode_image(image_path)\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "\tmodel=\"gpt-4o-mini\",\n",
    "\tmessages=[\n",
    "\t\t{\n",
    "\t\t\t\"role\": \"user\",\n",
    "\t\t\t\"content\": [\n",
    "\t\t\t\t{\n",
    "\t\t\t\t\t\"type\": \"text\",\n",
    "\t\t\t\t\t\"text\": \"What is in this image?\",\n",
    "\t\t\t\t},\n",
    "\t\t\t\t{\n",
    "\t\t\t\t\t\"type\": \"image_url\",\n",
    "\t\t\t\t\t\"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image}\"},\n",
    "\t\t\t\t},\n",
    "\t\t\t],\n",
    "\t\t}\n",
    "\t],\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beginner Exercise:\n",
    "\n",
    "**Task:**  Modify the code in \"Analyzing Image from Base64 Encoding\" section to analyze a *local* image file (e.g., an image file in the same directory as the notebook) and print the response.\n",
    "\n",
    "**Hint:**\n",
    "    - Make sure you have an image file (like JPEG or PNG) in the same directory as your notebook.\n",
    "    - Replace `\"path_to_your_image.jpg\"` with the actual filename of your local image file, e.g., `\"my_image.jpg\"`.\n",
    "    - Ensure that the `image_path` variable correctly points to your local image file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution for Beginner Exercise"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genaienv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
