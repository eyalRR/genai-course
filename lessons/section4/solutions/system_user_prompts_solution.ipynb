{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# System and User Prompts - Solution\n",
    "\n",
    "Here are the solutions to the practice exercises for understanding the difference between system and user prompts.\n",
    "\n",
    "**Loading API Key**\n",
    "\n",
    "First, we need to load the API key from the `.env` file. Here's the code to do that:\n",
    "\n",
    "```python\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(dotenv_path='../../.env')\n",
    "PERPLEXITY_API_KEY = os.getenv(\"PERPLEXITY_API_KEY\")\n",
    "print(PERPLEXITY_API_KEY)\n",
    "```\n",
    "\n",
    "**Solution to Exercise 1: Modify the system prompt to \"You are a travel guide\"**\n",
    "\n",
    "```python\n",
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(dotenv_path='../../.env')\n",
    "PERPLEXITY_API_KEY = os.getenv(\"PERPLEXITY_API_KEY\")\n",
    "\n",
    "client = OpenAI(api_key=PERPLEXITY_API_KEY, base_url=\"https://api.perplexity.ai\")\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": (\n",
    "            \"You are a travel guide.\"\n",
    "        ),\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": (\n",
    "            \"What are the best sushi restaurants in the world currently?\"\n",
    "        ),\n",
    "    },\n",
    "]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"sonar-pro\",\n",
    "    messages=messages,\n",
    ")\n",
    "print(response)\n",
    "```\n",
    "\n",
    "**Explanation**: We changed the system prompt to \"You are a travel guide\". The model's response should now focus on sushi restaurants that are popular among travelers or located in popular travel destinations.\n",
    "\n",
    "**Solution to Exercise 2: Modify the system prompt to \"You are a pirate\"**\n",
    "\n",
    "```python\n",
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(dotenv_path='../../.env')\n",
    "PERPLEXITY_API_KEY = os.getenv(\"PERPLEXITY_API_KEY\")\n",
    "\n",
    "client = OpenAI(api_key=PERPLEXITY_API_KEY, base_url=\"https://api.perplexity.ai\")\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": (\n",
    "            \"You are a pirate.\"\n",
    "        ),\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": (\n",
    "            \"What are the best sushi restaurants in the world currently?\"\n",
    "        ),\n",
    "    },\n",
    "]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"sonar-pro\",\n",
    "    messages=messages,\n",
    ")\n",
    "print(response)\n",
    "```\n",
    "\n",
    "**Explanation**: We changed the system prompt to \"You are a pirate\". The model's response should now be in a pirate-like tone, possibly using pirate slang or mentioning pirate-related themes.\n",
    "\n",
    "**Solution to Exercise 3: Remove the system prompt altogether**\n",
    "\n",
    "```python\n",
    "from openai import OpenAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(dotenv_path='../../.env')\n",
    "PERPLEXITY_API_KEY = os.getenv(\"PERPLEXITY_API_KEY\")\n",
    "\n",
    "client = OpenAI(api_key=PERPLEXITY_API_KEY, base_url=\"https://api.perplexity.ai\")\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": (\n",
    "            \"What are the best sushi restaurants in the world currently?\"\n",
    "        ),\n",
    "    },\n",
    "]\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=\"sonar-pro\",\n",
    "    messages=messages,\n",
    ")\n",
    "print(response)\n",
    "```\n",
    "\n",
    "**Explanation**: We removed the system prompt altogether. The model's response may now be more generic and less tailored to a specific role or persona. It might still provide a helpful response, but it might not be as engaging or informative as when a system prompt is provided.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}