{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# System and User Prompts\n",
    "\n",
    "Understanding the difference between system and user prompts is crucial for effectively controlling the behavior of LLMs. The system prompt sets the context and instructions for the model, while the user prompt provides the specific query or request.\n",
    "\n",
    "**Theory and Explanations**\n",
    "\n",
    "*   **System Prompt**: The system prompt is used to guide the model's overall behavior, tone, and style. It can be used to define the model's role, provide background information, or set constraints on its responses.\n",
    "*   **User Prompt**: The user prompt is the actual query or request that the user wants the model to answer. It should be clear, concise, and specific.\n",
    "*   **Impact on Model Behavior**: The system prompt has a significant impact on the model's behavior. By carefully crafting the system prompt, you can influence the model to generate more relevant, accurate, and helpful responses.\n",
    "\n",
    "**Example from Text**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "perplexity_api_key = os.getenv(\"PERPLEXITY_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": (\n",
    "            \"You are a helpful AI assistant.\"\n",
    "        ),\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": (\n",
    "            \"What are the best sushi restaurants in the world currently?\"\n",
    "        ),\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, the system prompt is \"You are a helpful AI assistant.\", which tells the model to act as a helpful assistant. The user prompt is \"What are the best sushi restaurants in the world currently?\", which is the user's query.\n",
    "\n",
    "**Practice Exercises**\n",
    "\n",
    "1.  Modify the system prompt to \"You are a travel guide\". Ask the same user prompt and observe the changes in the response. Does the model provide more travel-related information?\n",
    "2.  Modify the system prompt to \"You are a pirate\". Ask the same user prompt and observe the changes in the response. Does the model respond in a pirate-like tone?\n",
    "3.  Remove the system prompt altogether. Ask the same user prompt and observe the changes in the response. Does the model still provide a helpful response?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}