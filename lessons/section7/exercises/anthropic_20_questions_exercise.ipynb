{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Theory: Anthropic API & Gradio for a 20 Questions Game\n",
    "\n",
    "### Gradio Interface\n",
    "Gradio is used to create an interactive web interface for the game.\n",
    "- **`gr.ChatInterface`**: This is a high-level Gradio component that quickly creates a chatbot UI.\n",
    "  ```python\n",
    "  demo = gr.ChatInterface(\n",
    "      predict, # The function to call when a user sends a message\n",
    "      examples=[\"Start!\"], # Example inputs\n",
    "      chatbot=gr.Chatbot(placeholder=placeholder), # Customizing the chatbot display\n",
    "      type=\"messages\" # Using the newer messages format for history\n",
    "  )\n",
    "  # demo.launch() # Called in the code cell\n",
    "  ```\n",
    "- **`predict` function**: This function is the heart of the Gradio app. It takes the user's `message` and the `history` of the conversation.\n",
    "    - It appends the new user message to the history.\n",
    "    - It calls the Anthropic API.\n",
    "    - It returns the AI's response. The example code returns a dictionary with `role`, `content`, and `options` for quick replies (Yes/No buttons), which `gr.Chatbot` can process.\n",
    "- **`gr.Chatbot` and `placeholder`**: The `placeholder` provides initial instructions or a welcome message in the chat window.\n",
    "\n",
    "### 3. Game Logic\n",
    "- **History Management**: The `predict` function ensures the conversation `history` is correctly formatted (as a list of message dictionaries for `type=\"messages\"`) and passed to the Anthropic API.\n",
    "- **System Prompt**: This is key to guiding the AI's behavior. The example script instructs the AI to play 10 questions, ask yes/no questions, and respond in Hebrew."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "76950e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables from a .env file\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"ANTHROPIC_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eyalra\\AppData\\Local\\Temp\\ipykernel_30072\\4197186709.py:44: UserWarning: You have not specified a value for the `type` parameter. Defaulting to the 'tuples' format for chatbot messages, but this is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style dictionaries with 'role' and 'content' keys.\n",
      "  chatbot=gr.Chatbot(placeholder=placeholder),\n",
      "c:\\Users\\eyalra\\AppData\\Local\\miniconda3\\envs\\genaienv\\Lib\\site-packages\\gradio\\chat_interface.py:314: UserWarning: The type of the gr.Chatbot does not match the type of the gr.ChatInterface.The type of the gr.ChatInterface, 'messages', will be used.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7866\n",
      "* To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7866/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import anthropic\n",
    "import gradio as gr\n",
    "\n",
    "client = anthropic.Anthropic(api_key=api_key)\n",
    "\n",
    "def predict(message: str, history: list):\n",
    "    if client is None:\n",
    "        return \"Error: Anthropic client not initialized due to missing API key.\"\n",
    "        \n",
    "    # For type=\"messages\", history is a list of dicts: [{'role': 'user', 'content': '...'}, ...]\n",
    "    keys_to_keep = [\"role\", \"content\"]\n",
    "    history = [{k: d[k] for k in keys_to_keep if k in d} for d in history]\n",
    "    \n",
    "    history.append({\"role\": \"user\", \"content\": message})\n",
    "    \n",
    "    # Limit the game to roughly 10 questions from the AI (plus user turns)\n",
    "    # The system prompt also guides the AI on the number of questions.\n",
    "    if len(history) > 20: \n",
    "        history.append({\"role\": \"user\", \"content\": \"DONE\"})\n",
    "        \n",
    "    output = client.messages.create(\n",
    "        messages=history,  \n",
    "        model=\"claude-sonnet-4-20250514\", # User's specified model\n",
    "        max_tokens=1000,\n",
    "        system=\"You are guessing an object that the user is thinking of. You can ask 10 yes/no questions. Keep asking questions until the user says DONE, speak hebrew\"\n",
    "    )\n",
    "        \n",
    "    # For gr.ChatInterface with type=\"messages\", the function can return the assistant's message string directly.\n",
    "    # However, to support custom options like Yes/No buttons, returning a dict that gr.Chatbot can process is a valid pattern if the Chatbot is configured to handle it.\n",
    "    return {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": output.content[0].text,  \n",
    "        \"options\": [{\"value\": \"Yes\"}, {\"value\": \"No\"}]\n",
    "    }\n",
    "\n",
    "placeholder = \"\"\"\n",
    "<center><h1>10 Questions</h1><br>Think of a person, place, or thing. I'll ask you 10 yes/no questions to try and guess it.\n",
    "</center>\n",
    "\"\"\"\n",
    "\n",
    "demo = gr.ChatInterface(\n",
    "    predict,\n",
    "    examples=[\"Start!\"],\n",
    "    chatbot=gr.Chatbot(placeholder=placeholder),\n",
    "    type=\"messages\" \n",
    ")\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beginner Exercise\n",
    "\n",
    "Here's a simple task to get you started with modifying the game:\n",
    "\n",
    "**Task**: Change the AI's persona and the game's theme.\n",
    "\n",
    "1.  **Modify the `system` prompt**:\n",
    "    In the Python code cell above, find the line where the `system` prompt is defined within the `predict` function's call to `client.messages.create()`:\n",
    "    ```python\n",
    "    system=\"You are guessing an object that the user is thinking of. You can ask 10 yes/no questions. Keep asking questions until the user says DONE, speak hebrew\"\n",
    "    ```\n",
    "    Change this text to something different. For example:\n",
    "    *   Make the AI a space explorer guessing a planet: `\"You are a curious space explorer. The user is thinking of a planet in our solar system. Ask yes/no questions to guess it. Keep your responses short and inquisitive.\"`\n",
    "    *   Make the AI a food critic guessing a dish: `\"You are a renowned food critic with a refined palate. The user is thinking of a famous dish. Ask yes/no questions to identify it. Be a little bit snarky but polite.\"`\n",
    "\n",
    "2.  **Adjust the `placeholder` (Optional)**:\n",
    "    You might want to update the `placeholder` text assigned to the `gr.Chatbot` to match your new theme (defined in the code cell above).\n",
    "\n",
    "3.  **Run the code cell** and see how the AI's behavior changes when you interact with the Gradio interface!\n",
    "\n",
    "**Bonus Questions for Thought**:\n",
    "*   How does changing `max_tokens` affect the game?\n",
    "*   What happens if you remove the \"speak hebrew\" part from the original system prompt?\n",
    "*   Can you modify the `examples` in `gr.ChatInterface` to better suit your new theme?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c55132e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genaienv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
