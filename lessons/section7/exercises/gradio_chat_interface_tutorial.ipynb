{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 7: Gradio ChatInterface Tutorial\n",
    "\n",
    "Welcome to the `gr.ChatInterface` tutorial! Chatbots are a popular application of large language models (LLMs). Gradio provides `gr.ChatInterface()`, a high-level abstraction that allows you to create a chatbot UI quickly and easily."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "\n",
    "Ensure you have the latest version of Gradio installed. If you followed the main Gradio Quickstart tutorial, you should already have this. If not, or to make sure, run:\n",
    "\n",
    "```bash\n",
    "pip install --upgrade gradio\n",
    "```\n",
    "\n",
    "**Note:** Gradio requires Python 3.10 or higher."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining a Chat Function\n",
    "\n",
    "To create a chat application with `gr.ChatInterface()`, the first thing you should do is define your chat function. In the simplest case, your chat function should accept two arguments (the arguments can be named anything, but must be in this order):\n",
    "\n",
    "1.  `message`: A `str` representing the user's most recent message.\n",
    "2.  `history`: A list representing the previous conversation history. When using `type=\"messages\"` (which is highly recommended), the history is a list of OpenAI-style dictionaries. For example:\n",
    "    ```python\n",
    "    [\n",
    "        {\"role\": \"user\", \"content\": \"What is the capital of France?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Paris\"}\n",
    "    ]\n",
    "    ```\n",
    "\n",
    "Your chat function simply needs to return a `str` value, which is the chatbot's response based on the chat history and most recent message."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: A Chatbot that Randomly Responds\n",
    "\n",
    "Let's write a chat function that responds \"Yes\" or \"No\" randomly. This illustrates the basic structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "import random\n",
    "\n",
    "def random_response(message, history):\n",
    "    return random.choice([\"Yes\", \"No\"])\n",
    "\n",
    "print(\"Function 'random_response' defined.\")\n",
    "\n",
    "# To run this demo:\n",
    "# demo_random_chat = gr.ChatInterface(\n",
    "#     fn=random_response, \n",
    "#     type=\"messages\", # Always set type=\"messages\"\n",
    "#     title=\"Random Responder Bot\",\n",
    "#     description=\"This bot will randomly say Yes or No.\",\n",
    "#     examples=[\"Are you sure?\", \"Is today a good day?\"]\n",
    "# )\n",
    "# demo_random_chat.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Important Tip:** Always set `type=\"messages\"` in `gr.ChatInterface`. The default value (`type=\"tuples\"`) is deprecated and will be removed in a future version of Gradio. The `\"messages\"` type uses a more standard and flexible history format, making it easier to integrate with various language models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Streaming Chatbots\n",
    "\n",
    "For a more interactive experience, your chat function can `yield` a sequence of partial responses. Each yielded response replaces the previous one in the UI, creating a streaming effect where the chatbot's answer appears token by token.\n",
    "\n",
    "Here's an example of a streaming function structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import gradio as gr # Ensure gradio is imported if you run this cell standalone\n",
    "\n",
    "def slow_echo(message, history):\n",
    "    response_prefix = \"You typed: \"\n",
    "    full_response = \"\"\n",
    "    for i in range(len(message)):\n",
    "        time.sleep(0.1) # Simulate a delay for each character\n",
    "        full_response = response_prefix + message[:i+1]\n",
    "        yield full_response\n",
    "\n",
    "print(\"Function 'slow_echo' defined.\")\n",
    "\n",
    "# To run this demo:\n",
    "# demo_streaming_chat = gr.ChatInterface(\n",
    "#     fn=slow_echo,\n",
    "#     type=\"messages\",\n",
    "#     title=\"Streaming Echo Bot\",\n",
    "#     description=\"This bot slowly echoes your message, character by character.\"\n",
    "# )\n",
    "# demo_streaming_chat.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Simple Echo Chatbot\n",
    "\n",
    "Now it's your turn! Create a Gradio Chat Interface that:\n",
    "1.  Takes a user's message.\n",
    "2.  Has a Python chat function that simply echoes back the user's message, prepended with the text \"Echo: \".\n",
    "3.  Uses `gr.ChatInterface()` to display the chat.\n",
    "\n",
    "**Hints:**\n",
    "*   Your chat function will take `message` and `history` as arguments. You'll primarily use the `message` argument for this exercise.\n",
    "*   Remember to set `type=\"messages\"` in your `gr.ChatInterface` call.\n",
    "*   You can add a `title`, `description`, and `examples` to your `gr.ChatInterface` to make it more user-friendly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code for the Simple Echo Chatbot exercise here\n",
    "import gradio as gr\n",
    "\n",
    "# 1. Define the chat function\n",
    "def echo_bot(message, history):\n",
    "    # YOUR CODE HERE: Return the user's message, prefixed with \"Echo: \"\n",
    "    # Example: if message is \"Hello\", return \"Echo: Hello\"\n",
    "    pass\n",
    "\n",
    "# 2. Create the Gradio ChatInterface\n",
    "echo_chatbot_demo = gr.ChatInterface(\n",
    "    fn=None,  # YOUR CODE HERE: Pass your echo_bot function\n",
    "    type=\"messages\",\n",
    "    title=\"My First Echo Chatbot\",\n",
    "    description=\"Type something and I'll echo it back!\",\n",
    "    examples=[\"Hi there!\", \"Gradio is cool.\", \"What's for lunch?\"]\n",
    ")\n",
    "\n",
    "# 3. Launch the demo\n",
    "# echo_chatbot_demo.launch() # Uncomment to run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations on creating your first chatbot with `gr.ChatInterface`! There are many more features to explore, such as adding multimodal capabilities (handling images/files), customizing the UI further, adding additional inputs/outputs, and more. Refer to the official Gradio documentation for advanced usage."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}